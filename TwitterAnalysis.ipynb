{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SITC - Proyecto Final: Twitter football analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Crespo Bolaños, Priscila\n",
    "- Juliana Quiros, Gregorio\n",
    "- Murillo Ramos, David\n",
    "- Pascual Landa, Ignacio\n",
    "- Rodriguez Villalba, Álvaro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment classification for Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de datos etiquetados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda2/lib/python2.7/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9f5c7536</td>\n",
       "      <td>Recorriendo el #CampNou🏟 https://t.co/ZKZ1ERaiZS</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8e59cbaa</td>\n",
       "      <td>@FCBarcelona fera desde pequeno😲😲</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a2c38968</td>\n",
       "      <td>@sport Y el barca que haria sin Messi????? Ni ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51cf6477</td>\n",
       "      <td>Please RT!! #barcelona #fcbarcelona #Barca #fc...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2a1bb2a5</td>\n",
       "      <td>@NostradamusFCB Si parce que miedo, sólo el ba...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  polarity\n",
       "0  9f5c7536  Recorriendo el #CampNou🏟 https://t.co/ZKZ1ERaiZS   Neutral\n",
       "1  8e59cbaa                @FCBarcelona fera desde pequeno😲😲   Neutral\n",
       "2  a2c38968  @sport Y el barca que haria sin Messi????? Ni ...  Negative\n",
       "3  51cf6477  Please RT!! #barcelona #fcbarcelona #Barca #fc...   Neutral\n",
       "4  2a1bb2a5  @NostradamusFCB Si parce que miedo, sólo el ba...   Neutral"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Leemos el fichero de los datos sin etiquetar\n",
    "# General import and load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# if matplotlib is not set inline, you will not see plots\n",
    "#alternatives auto gtk gtk2 inline osx qt qt5 wx tk\n",
    "#%matplotlib auto\n",
    "#%matplotlib qt\n",
    "%matplotlib inline\n",
    "%run plot_learning_curve\n",
    "\n",
    "tweets = pd.read_csv('football-twitter/train.csv')\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          object\n",
       "text        object\n",
       "polarity    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral', 'Negative', 'Positive'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.polarity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polarity\n",
       "Negative    142\n",
       "Neutral     208\n",
       "Positive     61\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.groupby('polarity').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a0892abd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0892a810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets['polarity'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see there are more tweets labeled as Negative than Positive. WE will try to equalize those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          81\n",
       "text        81\n",
       "polarity    81\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_negative = tweets[tweets.polarity=='Negative']\n",
    "tweets_negative.head()\n",
    "tweets_toDelete = tweets_negative[:-61]\n",
    "tweets_toDelete.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9f5c7536</td>\n",
       "      <td>Recorriendo el #CampNou🏟 https://t.co/ZKZ1ERaiZS</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8e59cbaa</td>\n",
       "      <td>@FCBarcelona fera desde pequeno😲😲</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51cf6477</td>\n",
       "      <td>Please RT!! #barcelona #fcbarcelona #Barca #fc...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2a1bb2a5</td>\n",
       "      <td>@NostradamusFCB Si parce que miedo, sólo el ba...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7c2deb3b</td>\n",
       "      <td>@Matt_Santangelo Mino= No Barca.</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text polarity\n",
       "0  9f5c7536  Recorriendo el #CampNou🏟 https://t.co/ZKZ1ERaiZS  Neutral\n",
       "1  8e59cbaa                @FCBarcelona fera desde pequeno😲😲  Neutral\n",
       "3  51cf6477  Please RT!! #barcelona #fcbarcelona #Barca #fc...  Neutral\n",
       "4  2a1bb2a5  @NostradamusFCB Si parce que miedo, sólo el ba...  Neutral\n",
       "5  7c2deb3b                   @Matt_Santangelo Mino= No Barca.  Neutral"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets[~tweets.index.isin(tweets_toDelete.index)]\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polarity\n",
       "Negative     61\n",
       "Neutral     208\n",
       "Positive     61\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.groupby('polarity').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          208\n",
       "text        208\n",
       "polarity    208\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_neutral = tweets[tweets.polarity=='Neutral']\n",
    "tweets_neutral.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          147\n",
       "text        147\n",
       "polarity    147\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_neutraltoDelete = tweets_neutral[:-61]\n",
    "tweets_neutraltoDelete.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5c5d618c</td>\n",
       "      <td>Qué maravilla que este chico tocado por Dios, ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3fc87e2e</td>\n",
       "      <td>¡DE PIE DAMAS Y CABALLEROS! 💃🕴👏\\n#HOY se cu...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dfbfbf2f</td>\n",
       "      <td>⚽️🇪🇸| Barça\\n\\nEl partido de 'Dinho' ese día...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>43c66ae0</td>\n",
       "      <td>¡TREMENDO! 🙌 La brutal exhibición de Koke en ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1f103e4b</td>\n",
       "      <td>Que venga Arthur me tiene más emocionado que c...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  polarity\n",
       "8   5c5d618c  Qué maravilla que este chico tocado por Dios, ...  Positive\n",
       "15  3fc87e2e  ¡DE PIE DAMAS Y CABALLEROS! 💃🕴👏\\n#HOY se cu...  Positive\n",
       "19  dfbfbf2f  ⚽️🇪🇸| Barça\\n\\nEl partido de 'Dinho' ese día...  Positive\n",
       "23  43c66ae0  ¡TREMENDO! 🙌 La brutal exhibición de Koke en ...  Positive\n",
       "24  1f103e4b  Que venga Arthur me tiene más emocionado que c...  Positive"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets[~tweets.index.isin(tweets_neutraltoDelete.index)]\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a116a2490>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0871d890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets['polarity'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a more distributed number of negative, positive and neutral tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing & Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our corpus ready, we'll clean the tweets, removing stops words, tokenization, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/assistant/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/assistant/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Palabras parada\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "spanish_stopwords = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'de', u'la', u'que', u'el', u'en', u'y', u'a', u'los', u'del', u'se', u'las', u'por', u'un', u'para', u'con', u'no', u'una', u'su', u'al', u'lo', u'como', u'm\\xe1s', u'pero', u'sus', u'le', u'ya', u'o', u'este', u's\\xed', u'porque', u'esta', u'entre', u'cuando', u'muy', u'sin', u'sobre', u'tambi\\xe9n', u'me', u'hasta', u'hay', u'donde', u'quien', u'desde', u'todo', u'nos', u'durante', u'todos', u'uno', u'les', u'ni', u'contra', u'otros', u'ese', u'eso', u'ante', u'ellos', u'e', u'esto', u'm\\xed', u'antes', u'algunos', u'qu\\xe9', u'unos', u'yo', u'otro', u'otras', u'otra', u'\\xe9l', u'tanto', u'esa', u'estos', u'mucho', u'quienes', u'nada', u'muchos', u'cual', u'poco', u'ella', u'estar', u'estas', u'algunas', u'algo', u'nosotros', u'mi', u'mis', u't\\xfa', u'te', u'ti', u'tu', u'tus', u'ellas', u'nosotras', u'vosostros', u'vosostras', u'os', u'm\\xedo', u'm\\xeda', u'm\\xedos', u'm\\xedas', u'tuyo', u'tuya', u'tuyos', u'tuyas', u'suyo', u'suya', u'suyos', u'suyas', u'nuestro', u'nuestra', u'nuestros', u'nuestras', u'vuestro', u'vuestra', u'vuestros', u'vuestras', u'esos', u'esas', u'estoy', u'est\\xe1s', u'est\\xe1', u'estamos', u'est\\xe1is', u'est\\xe1n', u'est\\xe9', u'est\\xe9s', u'estemos', u'est\\xe9is', u'est\\xe9n', u'estar\\xe9', u'estar\\xe1s', u'estar\\xe1', u'estaremos', u'estar\\xe9is', u'estar\\xe1n', u'estar\\xeda', u'estar\\xedas', u'estar\\xedamos', u'estar\\xedais', u'estar\\xedan', u'estaba', u'estabas', u'est\\xe1bamos', u'estabais', u'estaban', u'estuve', u'estuviste', u'estuvo', u'estuvimos', u'estuvisteis', u'estuvieron', u'estuviera', u'estuvieras', u'estuvi\\xe9ramos', u'estuvierais', u'estuvieran', u'estuviese', u'estuvieses', u'estuvi\\xe9semos', u'estuvieseis', u'estuviesen', u'estando', u'estado', u'estada', u'estados', u'estadas', u'estad', u'he', u'has', u'ha', u'hemos', u'hab\\xe9is', u'han', u'haya', u'hayas', u'hayamos', u'hay\\xe1is', u'hayan', u'habr\\xe9', u'habr\\xe1s', u'habr\\xe1', u'habremos', u'habr\\xe9is', u'habr\\xe1n', u'habr\\xeda', u'habr\\xedas', u'habr\\xedamos', u'habr\\xedais', u'habr\\xedan', u'hab\\xeda', u'hab\\xedas', u'hab\\xedamos', u'hab\\xedais', u'hab\\xedan', u'hube', u'hubiste', u'hubo', u'hubimos', u'hubisteis', u'hubieron', u'hubiera', u'hubieras', u'hubi\\xe9ramos', u'hubierais', u'hubieran', u'hubiese', u'hubieses', u'hubi\\xe9semos', u'hubieseis', u'hubiesen', u'habiendo', u'habido', u'habida', u'habidos', u'habidas', u'soy', u'eres', u'es', u'somos', u'sois', u'son', u'sea', u'seas', u'seamos', u'se\\xe1is', u'sean', u'ser\\xe9', u'ser\\xe1s', u'ser\\xe1', u'seremos', u'ser\\xe9is', u'ser\\xe1n', u'ser\\xeda', u'ser\\xedas', u'ser\\xedamos', u'ser\\xedais', u'ser\\xedan', u'era', u'eras', u'\\xe9ramos', u'erais', u'eran', u'fui', u'fuiste', u'fue', u'fuimos', u'fuisteis', u'fueron', u'fuera', u'fueras', u'fu\\xe9ramos', u'fuerais', u'fueran', u'fuese', u'fueses', u'fu\\xe9semos', u'fueseis', u'fuesen', u'sintiendo', u'sentido', u'sentida', u'sentidos', u'sentidas', u'siente', u'sentid', u'tengo', u'tienes', u'tiene', u'tenemos', u'ten\\xe9is', u'tienen', u'tenga', u'tengas', u'tengamos', u'teng\\xe1is', u'tengan', u'tendr\\xe9', u'tendr\\xe1s', u'tendr\\xe1', u'tendremos', u'tendr\\xe9is', u'tendr\\xe1n', u'tendr\\xeda', u'tendr\\xedas', u'tendr\\xedamos', u'tendr\\xedais', u'tendr\\xedan', u'ten\\xeda', u'ten\\xedas', u'ten\\xedamos', u'ten\\xedais', u'ten\\xedan', u'tuve', u'tuviste', u'tuvo', u'tuvimos', u'tuvisteis', u'tuvieron', u'tuviera', u'tuvieras', u'tuvi\\xe9ramos', u'tuvierais', u'tuvieran', u'tuviese', u'tuvieses', u'tuvi\\xe9semos', u'tuvieseis', u'tuviesen', u'teniendo', u'tenido', u'tenida', u'tenidos', u'tenidas', u'tened']\n"
     ]
    }
   ],
   "source": [
    "print(spanish_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Signos de puntuación\n",
    "from string import punctuation\n",
    "non_words = list(punctuation)\n",
    "\n",
    "#we add spanish punctuation\n",
    "non_words.extend(['¿', '¡', '\\u200d', '—', '“', '”', '…', '\\U0001f929', '‘', '’'])\n",
    "non_words.extend(map(str,range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '\\xc2\\xbf',\n",
       " '\\xc2\\xa1',\n",
       " '\\\\u200d',\n",
       " '\\xe2\\x80\\x94',\n",
       " '\\xe2\\x80\\x9c',\n",
       " '\\xe2\\x80\\x9d',\n",
       " '\\xe2\\x80\\xa6',\n",
       " '\\\\U0001f929',\n",
       " '\\xe2\\x80\\x98',\n",
       " '\\xe2\\x80\\x99',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer       \n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "# based on http://www.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html\n",
    "stemmer = LancasterStemmer()\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    # remove non letters\n",
    "    text = ''.join([c for c in text if c not in non_words])\n",
    "    # tokenize\n",
    "    tokens =  tweet_tokenizer.tokenize(text)\n",
    "\n",
    "    # stem\n",
    "    try:\n",
    "        stems = stem_tokens(tokens, stemmer)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(text)\n",
    "        stems = ['']\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will categorize the sentiment.\n",
    "- Negative sentiments:0\n",
    "- Positive sentiments:1\n",
    "- Neutral sentiments:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    0.333333\n",
       "1    0.333333\n",
       "0    0.333333\n",
       "Name: polarity_bin, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['polarity_bin'] = 0\n",
    "tweets.polarity_bin[tweets.polarity=='Positive'] = 1\n",
    "tweets.polarity_bin[tweets.polarity=='Negative'] = 0\n",
    "tweets.polarity_bin[tweets.polarity=='Neutral'] = 2\n",
    "\n",
    "tweets.polarity_bin.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a binary classification problem, the score will be the Area Under Curve (roc_auc). We will use in this case the Linear Support Vector Classifier, and use the Gird Search to optimize the parameters to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the model with the optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Scores in every iteration', array([0.53846154, 0.44444444, 0.30555556, 0.44444444, 0.41666667]))\n",
      "Accuracy: 0.43 (+/- 0.15)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "            analyzer = 'word',\n",
    "            tokenizer = tokenize,\n",
    "            lowercase = True,\n",
    "            stop_words = spanish_stopwords,\n",
    "            max_features=5000\n",
    "            )\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('cls', LinearSVC()),\n",
    "])\n",
    "#Aprender el vocabulario\n",
    "tweets_features = vectorizer.fit_transform(tweets.text)\n",
    "tweets_features_nd = tweets_features.toarray()\n",
    "#Evaluacion del modelo\n",
    "scores = cross_val_score(pipeline, tweets.text, tweets.polarity_bin, cv=5)\n",
    "print(\"Scores in every iteration\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best score: ', 0.5136612021857924)\n",
      "('Best params: ', {'vect__ngram_range': [1, 1], 'cls__alpha': 1.0, 'vect__max_features': 2500})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "pipeline_NB = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('cls', MultinomialNB()),\n",
    "])\n",
    "#Aprender el vocabulario\n",
    "tweets_features = vectorizer.fit_transform(tweets.text)\n",
    "tweets_features_nd = tweets_features.toarray()\n",
    "\n",
    "param_grid = {    \n",
    "    'vect__max_features': [1000, 2500, 5000],\n",
    "    'vect__ngram_range': [[1, 1], [2, 2]],  # unigrams or bigrams\n",
    "    'cls__alpha': [0.1,0.5,1.0],\n",
    "} \n",
    "\n",
    "gs = GridSearchCV(pipeline_NB, param_grid)\n",
    "\n",
    "gs.fit(tweets.text, tweets.polarity_bin)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(\"Best score: \", gs.best_score_)\n",
    "print(\"Best params: \", gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  app.launch_new_instance()\n",
      "/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Scores in every iteration', array([0.61538462, 0.44444444, 0.30555556, 0.5       , 0.44444444]))\n",
      "Accuracy: 0.46 (+/- 0.20)\n"
     ]
    }
   ],
   "source": [
    "#Regresion lineal\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "pipeline_LogR = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('lr', LogisticRegression(n_jobs=-1)),\n",
    "])\n",
    "#Aprender el vocabulario\n",
    "tweets_features = vectorizer.fit_transform(tweets.text)\n",
    "tweets_features_nd = tweets_features.toarray()\n",
    "\n",
    "scores = cross_val_score(pipeline_LogR, tweets.text, tweets.polarity_bin, cv=5)\n",
    "print(\"Scores in every iteration\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Scores in every iteration', array([0.38461538, 0.33333333, 0.30555556, 0.38888889, 0.38888889]))\n",
      "Accuracy: 0.36 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "#Knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "pipeline_knn = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "])\n",
    "#Aprender el vocabulario\n",
    "tweets_features = vectorizer.fit_transform(tweets.text)\n",
    "tweets_features_nd = tweets_features.toarray()\n",
    "\n",
    "scores = cross_val_score(pipeline_knn, tweets.text, tweets.polarity_bin, cv=5)\n",
    "print(\"Scores in every iteration\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best score: ', 0.47540983606557374)\n",
      "('Best params: ', {'vect__ngram_range': [1, 1], 'mpl__hidden_layer_sizes': (100,), 'vect__max_features': 1000})\n"
     ]
    }
   ],
   "source": [
    "#MPL\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "pipeline_mpl = Pipeline([\n",
    "    ('vect', CountVectorizer(\n",
    "            analyzer = 'word',\n",
    "            tokenizer = tokenize,\n",
    "            lowercase = True,\n",
    "            stop_words = spanish_stopwords,\n",
    "            )),\n",
    "    ('mpl', MLPClassifier(max_iter=500)),\n",
    "])\n",
    "#Aprender el vocabulario\n",
    "tweets_features = vectorizer.fit_transform(tweets.text)\n",
    "tweets_features_nd = tweets_features.toarray()\n",
    "\n",
    "param_grid = {    \n",
    "    'vect__max_features': [1000, 3000, 4000],\n",
    "    'vect__ngram_range': [[1, 1], [2, 2]],  # unigrams or bigrams\n",
    "    'mpl__hidden_layer_sizes': [(100,), (200,)]\n",
    "} \n",
    "\n",
    "gs = GridSearchCV(pipeline_mpl, param_grid)\n",
    "\n",
    "gs.fit(tweets.text, tweets.polarity_bin)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(\"Best score: \", gs.best_score_)\n",
    "print(\"Best params: \", gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Scores in every iteration', array([0.41025641, 0.38888889, 0.47222222, 0.33333333, 0.33333333]))\n",
      "Accuracy: 0.39 (+/- 0.10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "#Decision Tree\n",
    "pipeline_dt = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('dt', tree.DecisionTreeClassifier()),\n",
    "])\n",
    "#Aprender el vocabulario\n",
    "tweets_features = vectorizer.fit_transform(tweets.text)\n",
    "tweets_features_nd = tweets_features.toarray()\n",
    "\n",
    "scores = cross_val_score(pipeline_dt, tweets.text, tweets.polarity_bin, cv=5)\n",
    "print(\"Scores in every iteration\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa24173d</td>\n",
       "      <td>Han robado por el método del alunizaje en la t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79cdded5</td>\n",
       "      <td>@BenditalocuraAt @Atleti @fhervas13 FELICIDADE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26fe7471</td>\n",
       "      <td>Dedicado para:\\n@Trigueros17 \\n@FCBarcelona ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d7d87d07</td>\n",
       "      <td>@Eribert42354852 El Barca aparte de ganar eso ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c4852036</td>\n",
       "      <td>Vengo 2/2 con los clasificados a Cuartos de Ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text\n",
       "0  aa24173d  Han robado por el método del alunizaje en la t...\n",
       "1  79cdded5  @BenditalocuraAt @Atleti @fhervas13 FELICIDADE...\n",
       "2  26fe7471  Dedicado para:\\n@Trigueros17 \\n@FCBarcelona ht...\n",
       "3  d7d87d07  @Eribert42354852 El Barca aparte de ganar eso ...\n",
       "4  c4852036  Vengo 2/2 con los clasificados a Cuartos de Ch..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargamos el fichero de tweets sin etiquetar\n",
    "tweets_nolabel = pd.read_csv('football-twitter/test_nolabel.csv')\n",
    "tweets_nolabel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_nolabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id      object\n",
       "text    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_nolabel.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#Entrenamos el modelo con los datos del corpus\n",
    "pipeline.fit(tweets.text, tweets.polarity_bin)\n",
    "#Realizamos las predicciones con los datos descargados directamente de Twitter\n",
    "#tweets['polarity'] = pipeline.predict(tweets_nolabel.text)\n",
    "#tweets[['tweet', 'polarity']].sample(20)\n",
    "\n",
    "polarity=pipeline.predict(tweets_nolabel.text)\n",
    "dataframeResult = pd.read_csv('football-twitter/test_nolabel.csv').filter(['id'], axis=1)\n",
    "dataframeResult['Polarity'] = polarity\n",
    "dataframeResult[:]\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([0], 'Negative')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([1], 'Positive')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([2], 'Neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframeResult.to_csv('out_svc.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#Entrenamos el modelo con los datos del corpus\n",
    "pipeline_NB.fit(tweets.text, tweets.polarity_bin)\n",
    "#Realizamos las predicciones con los datos descargados directamente de Twitter\n",
    "#tweets['polarity'] = pipeline.predict(tweets_nolabel.text)\n",
    "#tweets[['tweet', 'polarity']].sample(20)\n",
    "\n",
    "polarity=pipeline_NB.predict(tweets_nolabel.text)\n",
    "dataframeResult = pd.read_csv('football-twitter/test_nolabel.csv').filter(['id'], axis=1)\n",
    "dataframeResult['Polarity'] = polarity\n",
    "dataframeResult[:]\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([0], 'Negative')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([1], 'Positive')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([2], 'Neutral')\n",
    "dataframeResult.to_csv('out_nb.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#Entrenamos el modelo con los datos del corpus\n",
    "pipeline_LogR.fit(tweets.text, tweets.polarity_bin)\n",
    "#Realizamos las predicciones con los datos descargados directamente de Twitter\n",
    "#tweets['polarity'] = pipeline.predict(tweets_nolabel.text)\n",
    "#tweets[['tweet', 'polarity']].sample(20)\n",
    "\n",
    "polarity=pipeline_LogR.predict(tweets_nolabel.text)\n",
    "dataframeResult = pd.read_csv('football-twitter/test_nolabel.csv').filter(['id'], axis=1)\n",
    "dataframeResult['Polarity'] = polarity\n",
    "dataframeResult[:]\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([0], 'Negative')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([1], 'Positive')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([2], 'Neutral')\n",
    "dataframeResult.to_csv('out_LogR.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#Entrenamos el modelo con los datos del corpus\n",
    "pipeline_knn.fit(tweets.text, tweets.polarity_bin)\n",
    "#Realizamos las predicciones con los datos descargados directamente de Twitter\n",
    "#tweets['polarity'] = pipeline.predict(tweets_nolabel.text)\n",
    "#tweets[['tweet', 'polarity']].sample(20)\n",
    "\n",
    "polarity=pipeline_knn.predict(tweets_nolabel.text)\n",
    "dataframeResult = pd.read_csv('football-twitter/test_nolabel.csv').filter(['id'], axis=1)\n",
    "dataframeResult['Polarity'] = polarity\n",
    "dataframeResult[:]\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([0], 'Negative')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([1], 'Positive')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([2], 'Neutral')\n",
    "dataframeResult.to_csv('out_knn.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#Entrenamos el modelo con los datos del corpus\n",
    "pipeline_mpl.fit(tweets.text, tweets.polarity_bin)\n",
    "#Realizamos las predicciones con los datos descargados directamente de Twitter\n",
    "#tweets['polarity'] = pipeline.predict(tweets_nolabel.text)\n",
    "#tweets[['tweet', 'polarity']].sample(20)\n",
    "\n",
    "polarity=pipeline_mpl.predict(tweets_nolabel.text)\n",
    "dataframeResult = pd.read_csv('football-twitter/test_nolabel.csv').filter(['id'], axis=1)\n",
    "dataframeResult['Polarity'] = polarity\n",
    "dataframeResult[:]\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([0], 'Negative')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([1], 'Positive')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([2], 'Neutral')\n",
    "dataframeResult.to_csv('out_mpl.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#Entrenamos el modelo con los datos del corpus\n",
    "pipeline_dt.fit(tweets.text, tweets.polarity_bin)\n",
    "#Realizamos las predicciones con los datos descargados directamente de Twitter\n",
    "#tweets['polarity'] = pipeline.predict(tweets_nolabel.text)\n",
    "#tweets[['tweet', 'polarity']].sample(20)\n",
    "\n",
    "polarity=pipeline_dt.predict(tweets_nolabel.text)\n",
    "dataframeResult = pd.read_csv('football-twitter/test_nolabel.csv').filter(['id'], axis=1)\n",
    "dataframeResult['Polarity'] = polarity\n",
    "dataframeResult[:]\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([0], 'Negative')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([1], 'Positive')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([2], 'Neutral')\n",
    "dataframeResult.to_csv('out_dt.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
