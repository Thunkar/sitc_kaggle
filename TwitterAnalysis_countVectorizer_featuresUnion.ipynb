{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SITC - Proyecto Final: Twitter football analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Crespo Bolaños, Priscila\n",
    "- Juliana Quiros, Gregorio\n",
    "- Murillo Ramos, David\n",
    "- Pascual Landa, Ignacio\n",
    "- Rodriguez Villalba, Álvaro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment classification for Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de datos etiquetados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9f5c7536</td>\n",
       "      <td>Recorriendo el #CampNou🏟 https://t.co/ZKZ1ERaiZS</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8e59cbaa</td>\n",
       "      <td>@FCBarcelona fera desde pequeno😲😲</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a2c38968</td>\n",
       "      <td>@sport Y el barca que haria sin Messi????? Ni ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51cf6477</td>\n",
       "      <td>Please RT!! #barcelona #fcbarcelona #Barca #fc...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2a1bb2a5</td>\n",
       "      <td>@NostradamusFCB Si parce que miedo, sólo el ba...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  polarity\n",
       "0  9f5c7536   Recorriendo el #CampNou🏟 https://t.co/ZKZ1ERaiZS   Neutral\n",
       "1  8e59cbaa                  @FCBarcelona fera desde pequeno😲😲   Neutral\n",
       "2  a2c38968  @sport Y el barca que haria sin Messi????? Ni ...  Negative\n",
       "3  51cf6477  Please RT!! #barcelona #fcbarcelona #Barca #fc...   Neutral\n",
       "4  2a1bb2a5  @NostradamusFCB Si parce que miedo, sólo el ba...   Neutral"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Leemos el fichero de los datos sin etiquetar\n",
    "# General import and load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# if matplotlib is not set inline, you will not see plots\n",
    "#alternatives auto gtk gtk2 inline osx qt qt5 wx tk\n",
    "#%matplotlib auto\n",
    "#%matplotlib qt\n",
    "%matplotlib inline\n",
    "%run plot_learning_curve\n",
    "\n",
    "tweets = pd.read_csv('football-twitter/train.csv')\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          object\n",
       "text        object\n",
       "polarity    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral', 'Negative', 'Positive'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.polarity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polarity\n",
       "Negative    142\n",
       "Neutral     208\n",
       "Positive     61\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.groupby('polarity').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a0f9704e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD8CAYAAACW/ATfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a0932e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets['polarity'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see there are more tweets labeled as Negative than Positive. WE will try to equalize those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          81\n",
       "text        81\n",
       "polarity    81\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_negative = tweets[tweets.polarity=='Negative']\n",
    "tweets_negative.head()\n",
    "tweets_toDelete = tweets_negative[:-61]\n",
    "tweets_toDelete.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9f5c7536</td>\n",
       "      <td>Recorriendo el #CampNou🏟 https://t.co/ZKZ1ERaiZS</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8e59cbaa</td>\n",
       "      <td>@FCBarcelona fera desde pequeno😲😲</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51cf6477</td>\n",
       "      <td>Please RT!! #barcelona #fcbarcelona #Barca #fc...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2a1bb2a5</td>\n",
       "      <td>@NostradamusFCB Si parce que miedo, sólo el ba...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7c2deb3b</td>\n",
       "      <td>@Matt_Santangelo Mino= No Barca.</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text polarity\n",
       "0  9f5c7536   Recorriendo el #CampNou🏟 https://t.co/ZKZ1ERaiZS  Neutral\n",
       "1  8e59cbaa                  @FCBarcelona fera desde pequeno😲😲  Neutral\n",
       "3  51cf6477  Please RT!! #barcelona #fcbarcelona #Barca #fc...  Neutral\n",
       "4  2a1bb2a5  @NostradamusFCB Si parce que miedo, sólo el ba...  Neutral\n",
       "5  7c2deb3b                   @Matt_Santangelo Mino= No Barca.  Neutral"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets[~tweets.index.isin(tweets_toDelete.index)]\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polarity\n",
       "Negative     61\n",
       "Neutral     208\n",
       "Positive     61\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.groupby('polarity').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          208\n",
       "text        208\n",
       "polarity    208\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_neutral = tweets[tweets.polarity=='Neutral']\n",
    "tweets_neutral.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          147\n",
       "text        147\n",
       "polarity    147\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_neutraltoDelete = tweets_neutral[:-61]\n",
    "tweets_neutraltoDelete.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5c5d618c</td>\n",
       "      <td>Qué maravilla que este chico tocado por Dios, ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3fc87e2e</td>\n",
       "      <td>¡DE PIE DAMAS Y CABALLEROS! 💃🕴👏\\n#HOY se cumpl...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dfbfbf2f</td>\n",
       "      <td>⚽️🇪🇸| Barça\\n\\nEl partido de 'Dinho' ese día, ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>43c66ae0</td>\n",
       "      <td>¡TREMENDO! 🙌 La brutal exhibición de Koke en e...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1f103e4b</td>\n",
       "      <td>Que venga Arthur me tiene más emocionado que c...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  polarity\n",
       "8   5c5d618c  Qué maravilla que este chico tocado por Dios, ...  Positive\n",
       "15  3fc87e2e  ¡DE PIE DAMAS Y CABALLEROS! 💃🕴👏\\n#HOY se cumpl...  Positive\n",
       "19  dfbfbf2f  ⚽️🇪🇸| Barça\\n\\nEl partido de 'Dinho' ese día, ...  Positive\n",
       "23  43c66ae0  ¡TREMENDO! 🙌 La brutal exhibición de Koke en e...  Positive\n",
       "24  1f103e4b  Que venga Arthur me tiene más emocionado que c...  Positive"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets[~tweets.index.isin(tweets_neutraltoDelete.index)]\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10814b390>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD8CAYAAACINTRsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNeR/AdRi2FXiF0sNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0f9f3208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets['polarity'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a more distributed number of negative, positive and neutral tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing & Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our corpus ready, we'll clean the tweets, removing stops words, tokenization, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/priscilacb/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/priscilacb/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Palabras parada\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "spanish_stopwords = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'más', 'pero', 'sus', 'le', 'ya', 'o', 'este', 'sí', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'también', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'mí', 'antes', 'algunos', 'qué', 'unos', 'yo', 'otro', 'otras', 'otra', 'él', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 'tú', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', 'vosostros', 'vosostras', 'os', 'mío', 'mía', 'míos', 'mías', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas', 'estoy', 'estás', 'está', 'estamos', 'estáis', 'están', 'esté', 'estés', 'estemos', 'estéis', 'estén', 'estaré', 'estarás', 'estará', 'estaremos', 'estaréis', 'estarán', 'estaría', 'estarías', 'estaríamos', 'estaríais', 'estarían', 'estaba', 'estabas', 'estábamos', 'estabais', 'estaban', 'estuve', 'estuviste', 'estuvo', 'estuvimos', 'estuvisteis', 'estuvieron', 'estuviera', 'estuvieras', 'estuviéramos', 'estuvierais', 'estuvieran', 'estuviese', 'estuvieses', 'estuviésemos', 'estuvieseis', 'estuviesen', 'estando', 'estado', 'estada', 'estados', 'estadas', 'estad', 'he', 'has', 'ha', 'hemos', 'habéis', 'han', 'haya', 'hayas', 'hayamos', 'hayáis', 'hayan', 'habré', 'habrás', 'habrá', 'habremos', 'habréis', 'habrán', 'habría', 'habrías', 'habríamos', 'habríais', 'habrían', 'había', 'habías', 'habíamos', 'habíais', 'habían', 'hube', 'hubiste', 'hubo', 'hubimos', 'hubisteis', 'hubieron', 'hubiera', 'hubieras', 'hubiéramos', 'hubierais', 'hubieran', 'hubiese', 'hubieses', 'hubiésemos', 'hubieseis', 'hubiesen', 'habiendo', 'habido', 'habida', 'habidos', 'habidas', 'soy', 'eres', 'es', 'somos', 'sois', 'son', 'sea', 'seas', 'seamos', 'seáis', 'sean', 'seré', 'serás', 'será', 'seremos', 'seréis', 'serán', 'sería', 'serías', 'seríamos', 'seríais', 'serían', 'era', 'eras', 'éramos', 'erais', 'eran', 'fui', 'fuiste', 'fue', 'fuimos', 'fuisteis', 'fueron', 'fuera', 'fueras', 'fuéramos', 'fuerais', 'fueran', 'fuese', 'fueses', 'fuésemos', 'fueseis', 'fuesen', 'sintiendo', 'sentido', 'sentida', 'sentidos', 'sentidas', 'siente', 'sentid', 'tengo', 'tienes', 'tiene', 'tenemos', 'tenéis', 'tienen', 'tenga', 'tengas', 'tengamos', 'tengáis', 'tengan', 'tendré', 'tendrás', 'tendrá', 'tendremos', 'tendréis', 'tendrán', 'tendría', 'tendrías', 'tendríamos', 'tendríais', 'tendrían', 'tenía', 'tenías', 'teníamos', 'teníais', 'tenían', 'tuve', 'tuviste', 'tuvo', 'tuvimos', 'tuvisteis', 'tuvieron', 'tuviera', 'tuvieras', 'tuviéramos', 'tuvierais', 'tuvieran', 'tuviese', 'tuvieses', 'tuviésemos', 'tuvieseis', 'tuviesen', 'teniendo', 'tenido', 'tenida', 'tenidos', 'tenidas', 'tened']\n"
     ]
    }
   ],
   "source": [
    "print(spanish_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Signos de puntuación\n",
    "from string import punctuation\n",
    "non_words = list(punctuation)\n",
    "\n",
    "#we add spanish punctuation\n",
    "non_words.extend(['¿', '¡', '\\u200d', '—', '“', '”', '…', '\\U0001f929', '‘', '’'])\n",
    "non_words.extend(map(str,range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '¿',\n",
       " '¡',\n",
       " '\\u200d',\n",
       " '—',\n",
       " '“',\n",
       " '”',\n",
       " '…',\n",
       " '\\U0001f929',\n",
       " '‘',\n",
       " '’',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer       \n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "# based on http://www.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html\n",
    "stemmer = LancasterStemmer()\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    # remove non letters\n",
    "    text = ''.join([c for c in text if c not in non_words])\n",
    "    # tokenize\n",
    "    tokens =  tweet_tokenizer.tokenize(text)\n",
    "\n",
    "    # stem\n",
    "    try:\n",
    "        stems = stem_tokens(tokens, stemmer)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(text)\n",
    "        stems = ['']\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will categorize the sentiment.\n",
    "- Negative sentiments:0\n",
    "- Positive sentiments:1\n",
    "- Neutral sentiments:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    0.333333\n",
       "1    0.333333\n",
       "0    0.333333\n",
       "Name: polarity_bin, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['polarity_bin'] = 0\n",
    "tweets.polarity_bin[tweets.polarity=='Positive'] = 1\n",
    "tweets.polarity_bin[tweets.polarity=='Negative'] = 0\n",
    "tweets.polarity_bin[tweets.polarity=='Neutral'] = 2\n",
    "\n",
    "tweets.polarity_bin.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a binary classification problem, the score will be the Area Under Curve (roc_auc). We will use in this case the Linear Support Vector Classifier, and use the Gird Search to optimize the parameters to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the model with the optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.524590163934\n",
      "Best params:  {'cls__C': 0.2, 'cls__loss': 'hinge', 'cls__max_iter': 500}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "ngrams_featurizer = Pipeline([\n",
    "  ('count_vectorizer',  CountVectorizer(ngram_range = (1, 3), encoding = 'ISO-8859-1', \n",
    "                                        tokenizer=tokenize)),\n",
    "  ('tfidf_transformer', TfidfTransformer())\n",
    "])\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "            analyzer = 'word',\n",
    "            tokenizer = tokenize,\n",
    "            lowercase = True,\n",
    "            stop_words = spanish_stopwords,\n",
    "            max_features=5000\n",
    "            )\n",
    "\n",
    "## All the steps of the Pipeline should end with a sparse vector as the input data\n",
    "pipeline = Pipeline([\n",
    "       ('features', FeatureUnion([\n",
    "                    ('words', TfidfVectorizer(tokenizer=tokenize)),\n",
    "                    ('ngrams', ngrams_featurizer),\n",
    "                    ('lda', Pipeline([ \n",
    "                                ('vect', vectorizer),\n",
    "                                ('lda',  LatentDirichletAllocation(n_topics=4, max_iter=5,\n",
    "                                                       learning_method='online', \n",
    "                                                       learning_offset=50.,\n",
    "                                                       random_state=0))\n",
    "                            ])),\n",
    "                ])),\n",
    "        ('cls', LinearSVC())  # classifier\n",
    "    ])\n",
    "\n",
    "#Aprender el vocabulario\n",
    "tweets_features = vectorizer.fit_transform(tweets.text)\n",
    "tweets_features_nd = tweets_features.toarray()\n",
    "\n",
    "param_grid = {    \n",
    "    'cls__C': (0.2, 0.5, 0.7),\n",
    "    'cls__loss': ('hinge', 'squared_hinge'),\n",
    "    'cls__max_iter': (500, 1000)\n",
    "} \n",
    "gs_svc = GridSearchCV(pipeline, param_grid)\n",
    "gs_svc.fit(tweets.text, tweets.polarity_bin)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(\"Best score: \", gs_svc.best_score_)\n",
    "print(\"Best params: \", gs_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best score: ', 0.5136612021857924)\n",
      "('Best params: ', {'vect__ngram_range': [1, 1], 'cls__alpha': 1.0, 'vect__max_features': 2500})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "pipeline_NB = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('cls', MultinomialNB()),\n",
    "])\n",
    "#Aprender el vocabulario\n",
    "tweets_features = vectorizer.fit_transform(tweets.text)\n",
    "tweets_features_nd = tweets_features.toarray()\n",
    "\n",
    "param_grid = {    \n",
    "    'vect__max_features': [1000, 2500, 5000],\n",
    "    'vect__ngram_range': [[1, 1], [2, 2]],  # unigrams or bigrams\n",
    "    'cls__alpha': [0.5, 1.0],\n",
    "} \n",
    "\n",
    "gs_nb = GridSearchCV(pipeline_NB, param_grid)\n",
    "\n",
    "gs_nb.fit(tweets.text, tweets.polarity_bin)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(\"Best score: \", gs_nb.best_score_)\n",
    "print(\"Best params: \", gs_nb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  app.launch_new_instance()\n",
      "/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Scores in every iteration', array([0.61538462, 0.44444444, 0.30555556, 0.5       , 0.44444444]))\n",
      "Accuracy: 0.46 (+/- 0.20)\n"
     ]
    }
   ],
   "source": [
    "#Regresion lineal\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "pipeline_LogR = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('lr', LogisticRegression(n_jobs=-1)),\n",
    "])\n",
    "#Aprender el vocabulario\n",
    "tweets_features = vectorizer.fit_transform(tweets.text)\n",
    "tweets_features_nd = tweets_features.toarray()\n",
    "\n",
    "scores = cross_val_score(pipeline_LogR, tweets.text, tweets.polarity_bin, cv=5)\n",
    "print(\"Scores in every iteration\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Scores in every iteration', array([0.38461538, 0.33333333, 0.30555556, 0.38888889, 0.38888889]))\n",
      "Accuracy: 0.36 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "#Knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "pipeline_knn = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "])\n",
    "#Aprender el vocabulario\n",
    "tweets_features = vectorizer.fit_transform(tweets.text)\n",
    "tweets_features_nd = tweets_features.toarray()\n",
    "\n",
    "scores = cross_val_score(pipeline_knn, tweets.text, tweets.polarity_bin, cv=5)\n",
    "print(\"Scores in every iteration\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best score: ', 0.48633879781420764)\n",
      "('Best params: ', {'vect__ngram_range': [1, 1], 'mpl__hidden_layer_sizes': (100,), 'vect__max_features': 4000})\n"
     ]
    }
   ],
   "source": [
    "#MPL\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "pipeline_mpl = Pipeline([\n",
    "    ('vect', CountVectorizer(\n",
    "            analyzer = 'word',\n",
    "            tokenizer = tokenize,\n",
    "            lowercase = True,\n",
    "            stop_words = spanish_stopwords,\n",
    "            )),\n",
    "    ('mpl', MLPClassifier(max_iter=500)),\n",
    "])\n",
    "#Aprender el vocabulario\n",
    "tweets_features = vectorizer.fit_transform(tweets.text)\n",
    "tweets_features_nd = tweets_features.toarray()\n",
    "\n",
    "param_grid = {    \n",
    "    'vect__max_features': [1000, 3000, 4000],\n",
    "    'vect__ngram_range': [[1, 1], [2, 2]],  # unigrams or bigrams\n",
    "    'mpl__hidden_layer_sizes': [(100,), (200,)]\n",
    "} \n",
    "\n",
    "gs_mpl = GridSearchCV(pipeline_mpl, param_grid)\n",
    "\n",
    "gs_mpl.fit(tweets.text, tweets.polarity_bin)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(\"Best score: \", gs_mpl.best_score_)\n",
    "print(\"Best params: \", gs_mpl.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "#Decision Tree\n",
    "pipeline_dt = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('dt', tree.DecisionTreeClassifier()),\n",
    "])\n",
    "#Aprender el vocabulario\n",
    "tweets_features = vectorizer.fit_transform(tweets.text)\n",
    "tweets_features_nd = tweets_features.toarray()\n",
    "\n",
    "scores = cross_val_score(pipeline_dt, tweets.text, tweets.polarity_bin, cv=5)\n",
    "print(\"Scores in every iteration\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cargamos el fichero de tweets sin etiquetar\n",
    "tweets_nolabel = pd.read_csv('football-twitter/test_nolabel.csv')\n",
    "tweets_nolabel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_nolabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_nolabel.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Entrenamos el modelo con los datos del corpus\n",
    "pipeline.fit(tweets.text, tweets.polarity_bin)\n",
    "#Realizamos las predicciones con los datos descargados directamente de Twitter\n",
    "#tweets['polarity'] = pipeline.predict(tweets_nolabel.text)\n",
    "#tweets[['tweet', 'polarity']].sample(20)\n",
    "\n",
    "polarity=pipeline.predict(tweets_nolabel.text)\n",
    "dataframeResult = pd.read_csv('football-twitter/test_nolabel.csv').filter(['id'], axis=1)\n",
    "dataframeResult['Polarity'] = polarity\n",
    "dataframeResult[:]\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([0], 'Negative')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([1], 'Positive')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([2], 'Neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframeResult.to_csv('out_svc.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Realizamos las predicciones con los datos descargados directamente de Twitter\n",
    "#tweets['polarity'] = pipeline.predict(tweets_nolabel.text)\n",
    "#tweets[['tweet', 'polarity']].sample(20)\n",
    "\n",
    "polarity=gs_nb.predict(tweets_nolabel.text)\n",
    "dataframeResult = pd.read_csv('football-twitter/test_nolabel.csv').filter(['id'], axis=1)\n",
    "dataframeResult['Polarity'] = polarity\n",
    "dataframeResult[:]\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([0], 'Negative')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([1], 'Positive')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([2], 'Neutral')\n",
    "dataframeResult.to_csv('out_nb.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Entrenamos el modelo con los datos del corpus\n",
    "pipeline_LogR.fit(tweets.text, tweets.polarity_bin)\n",
    "#Realizamos las predicciones con los datos descargados directamente de Twitter\n",
    "#tweets['polarity'] = pipeline.predict(tweets_nolabel.text)\n",
    "#tweets[['tweet', 'polarity']].sample(20)\n",
    "\n",
    "polarity=pipeline_LogR.predict(tweets_nolabel.text)\n",
    "dataframeResult = pd.read_csv('football-twitter/test_nolabel.csv').filter(['id'], axis=1)\n",
    "dataframeResult['Polarity'] = polarity\n",
    "dataframeResult[:]\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([0], 'Negative')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([1], 'Positive')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([2], 'Neutral')\n",
    "dataframeResult.to_csv('out_LogR.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Entrenamos el modelo con los datos del corpus\n",
    "pipeline_knn.fit(tweets.text, tweets.polarity_bin)\n",
    "#Realizamos las predicciones con los datos descargados directamente de Twitter\n",
    "#tweets['polarity'] = pipeline.predict(tweets_nolabel.text)\n",
    "#tweets[['tweet', 'polarity']].sample(20)\n",
    "\n",
    "polarity=pipeline_knn.predict(tweets_nolabel.text)\n",
    "dataframeResult = pd.read_csv('football-twitter/test_nolabel.csv').filter(['id'], axis=1)\n",
    "dataframeResult['Polarity'] = polarity\n",
    "dataframeResult[:]\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([0], 'Negative')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([1], 'Positive')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([2], 'Neutral')\n",
    "dataframeResult.to_csv('out_knn.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Realizamos las predicciones con los datos descargados directamente de Twitter\n",
    "#tweets['polarity'] = pipeline.predict(tweets_nolabel.text)\n",
    "#tweets[['tweet', 'polarity']].sample(20)\n",
    "\n",
    "polarity=gs_mpl.predict(tweets_nolabel.text)\n",
    "dataframeResult = pd.read_csv('football-twitter/test_nolabel.csv').filter(['id'], axis=1)\n",
    "dataframeResult['Polarity'] = polarity\n",
    "dataframeResult[:]\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([0], 'Negative')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([1], 'Positive')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([2], 'Neutral')\n",
    "dataframeResult.to_csv('out_mpl.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Entrenamos el modelo con los datos del corpus\n",
    "pipeline_dt.fit(tweets.text, tweets.polarity_bin)\n",
    "#Realizamos las predicciones con los datos descargados directamente de Twitter\n",
    "#tweets['polarity'] = pipeline.predict(tweets_nolabel.text)\n",
    "#tweets[['tweet', 'polarity']].sample(20)\n",
    "\n",
    "polarity=pipeline_dt.predict(tweets_nolabel.text)\n",
    "dataframeResult = pd.read_csv('football-twitter/test_nolabel.csv').filter(['id'], axis=1)\n",
    "dataframeResult['Polarity'] = polarity\n",
    "dataframeResult[:]\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([0], 'Negative')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([1], 'Positive')\n",
    "dataframeResult['Polarity'] = dataframeResult['Polarity'].replace([2], 'Neutral')\n",
    "dataframeResult.to_csv('out_dt.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
